#!/usr/bin/env python3
"""
Scan ICS files across all cities and report distinct PRODID values (ICS platforms).
Updates docs/prodid.md with a table of platforms, descriptions, and which cities use them.
"""

import re
import sys
from pathlib import Path
from collections import defaultdict

# Map raw PRODID patterns to normalized platform names and descriptions.
# Order matters: first match wins.
PLATFORM_MAP = [
    (r'ECPv\d', 'The Events Calendar (WordPress)', 'WordPress plugin (aka "Tribe Events"). PRODID includes site name + ECP version.'),
    (r'wp-events-plugin\.com', 'Modern Events Calendar (WordPress)', 'WordPress plugin by Webnus. PRODID references wp-events-plugin.com.'),
    (r'Meetup//Meetup Calendar', 'Meetup', 'ICS export from meetup.com groups.'),
    (r'tockify\.com', 'Tockify', 'Embeddable calendar widget with public ICS feeds.'),
    (r'Google Inc//Google Calendar', 'Google Calendar', 'Public Google Calendar ICS export.'),
    (r'iCalendar-Ruby', 'Localist', 'Campus/community event platform by Concept3D (uses iCalendar-Ruby gem). Common at universities.'),
    (r'Springshare//LibCal', 'LibCal (Springshare)', 'Library event management platform.'),
    (r'rianjs/ical\.net', 'CivicPlus (ical.net)', 'Government CMS using ical.net library. Common for city/county websites.'),
    (r'BedeWork', 'Bedework', 'Open-source enterprise calendar (Java). Used by Duke and some universities.'),
    (r'MembershipWorks', 'MembershipWorks', 'Membership management platform with event calendar.'),
    (r'growthzone\.com', 'GrowthZone', 'Chamber of commerce / association management platform.'),
    (r'Indiana University', 'Localist', 'Campus/community event platform by Concept3D (Indiana University instance).'),
    (r'Golang ICS Library', 'Golang ICS', 'Events generated by Go ical library.'),
    (r'maxpreps\.com', 'MaxPreps', 'High school sports schedules.'),
    (r'bibliocommons\.com', 'BiblioCommons', 'Library discovery platform with event listings.'),
]


def classify_prodid(prodid: str) -> tuple[str, str] | None:
    """Return (platform_name, description) for a PRODID string, or None to skip."""
    # Skip our own scrapers and combined feeds
    if 'Community Calendar//' in prodid:
        return None
    for pattern, name, desc in PLATFORM_MAP:
        if re.search(pattern, prodid):
            return name, desc
    # Skip unrecognized PRODIDs (likely our own scrapers with custom PRODIDs)
    return None


def scan_cities(repo_root: Path) -> dict:
    """Scan all cities and return {platform: {description, cities: {city: [files]}}}."""
    cities_dir = repo_root / 'cities'
    platforms = {}  # name -> {desc, cities: {city: [files]}}

    for city_dir in sorted(cities_dir.iterdir()):
        if not city_dir.is_dir():
            continue
        city = city_dir.name
        for ics_file in sorted(city_dir.glob('*.ics')):
            if ics_file.name == 'combined.ics':
                continue
            try:
                # Read just the header (first 50 lines) for efficiency
                with open(ics_file, 'r', errors='replace') as f:
                    header = ''
                    for i, line in enumerate(f):
                        header += line
                        if i > 50:
                            break
            except Exception:
                continue

            match = re.search(r'PRODID[;:](.+)', header)
            if not match:
                continue
            prodid = match.group(1).strip()
            result = classify_prodid(prodid)
            if result is None:
                continue
            name, desc = result

            if name not in platforms:
                platforms[name] = {'desc': desc, 'cities': defaultdict(list)}
            platforms[name]['cities'][city].append(ics_file.stem)

    return platforms


def generate_markdown(platforms: dict) -> str:
    """Generate the docs/prodid.md content."""
    lines = [
        '# ICS Platforms (PRODID Report)',
        '',
        'Auto-generated by `scripts/prodid.py`. Shows the distinct ICS platforms',
        'used across all city feeds, identified by their PRODID header.',
        '',
    ]

    # Summary table
    lines.append('## Summary')
    lines.append('')
    lines.append('| Platform | Description | Cities | Feeds |')
    lines.append('|----------|-------------|--------|------:|')

    # Sort by total feed count descending
    sorted_platforms = sorted(
        platforms.items(),
        key=lambda x: sum(len(files) for files in x[1]['cities'].values()),
        reverse=True
    )

    for name, info in sorted_platforms:
        cities = sorted(info['cities'].keys())
        total_feeds = sum(len(files) for files in info['cities'].values())
        city_list = ', '.join(cities)
        lines.append(f'| **{name}** | {info["desc"]} | {city_list} | {total_feeds} |')

    # Detail by platform
    lines.append('')
    lines.append('## Detail')
    lines.append('')

    for name, info in sorted_platforms:
        total_feeds = sum(len(files) for files in info['cities'].values())
        lines.append(f'### {name} ({total_feeds} feeds)')
        lines.append('')
        lines.append(f'{info["desc"]}')
        lines.append('')
        for city in sorted(info['cities'].keys()):
            files = info['cities'][city]
            lines.append(f'**{city}** ({len(files)}): {", ".join(sorted(files))}')
            lines.append('')

    return '\n'.join(lines)


def main():
    repo_root = Path(__file__).parent.parent
    platforms = scan_cities(repo_root)
    md = generate_markdown(platforms)

    out_path = repo_root / 'docs' / 'prodid.md'
    out_path.write_text(md)
    print(f'Wrote {out_path}')

    # Also print summary to stdout
    total_feeds = sum(
        sum(len(f) for f in p['cities'].values())
        for p in platforms.values()
    )
    print(f'{len(platforms)} platforms, {total_feeds} feeds across {len(set(c for p in platforms.values() for c in p["cities"]))} cities')


if __name__ == '__main__':
    main()
