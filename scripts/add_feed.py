#!/usr/bin/env python3
"""Add a new ICS feed to the pipeline.

This script automates the steps for integrating an ICS feed:
1. Test the feed URL to verify it returns valid ICS with events
2. Add curl command to the GitHub Actions workflow

Note: feeds.txt is auto-generated by sync_feeds_txt.py ‚Äî this script does not update it.

Usage:
    python scripts/add_feed.py "https://example.com/events/?ical=1" toronto "Example Events"
    python scripts/add_feed.py "https://meetup.com/group/events/ical/" toronto "Meetup Group" --test
    python scripts/add_feed.py URL city "Source Name" --dry-run
"""

import argparse
import re
import subprocess
import sys
from pathlib import Path
from urllib.parse import urlparse

import shutil

# Repository root
ROOT = Path(__file__).parent.parent
WORKFLOW_PATH = ROOT / ".github/workflows/generate-calendar.yml"


def count_actionlint_errors(path: Path) -> int | None:
    """Count actionlint errors on a workflow file. Returns None if actionlint not available."""
    actionlint = shutil.which('actionlint')
    if not actionlint:
        return None
    result = subprocess.run([actionlint, str(path)], capture_output=True, text=True)
    return result.stdout.count('\n') if result.stdout else 0


def validate_workflow(path: Path, prev_error_count: int | None) -> bool:
    """Validate that editing the workflow didn't introduce new actionlint errors."""
    if prev_error_count is None:
        print("‚ö†Ô∏è  actionlint not available, skipping validation")
        return True
    new_count = count_actionlint_errors(path)
    if new_count > prev_error_count:
        print(f"‚ùå actionlint: edit introduced new errors ({prev_error_count} ‚Üí {new_count})")
        return False
    print(f"‚úÖ actionlint: no new errors ({new_count} pre-existing)")
    return True


def slugify(url: str) -> str:
    """Generate a filename slug from a URL."""
    parsed = urlparse(url)
    
    # Special case for Meetup
    if 'meetup.com' in parsed.netloc:
        # Extract group name from /group-name/events/ical/
        match = re.search(r'meetup\.com/([^/]+)', url)
        if match:
            group = match.group(1)
            # Clean up the group name
            group = re.sub(r'[^a-zA-Z0-9]+', '_', group).lower().strip('_')
            return f"meetup_{group}"
    
    # Special case for Tockify
    if 'tockify.com' in parsed.netloc:
        match = re.search(r'/ics/([^/]+)', url)
        if match:
            return f"tockify_{match.group(1)}"
    
    # General case: use domain + path
    domain = parsed.netloc.replace('www.', '').split('.')[0]
    path_parts = [p for p in parsed.path.split('/') if p and p not in ('events', 'ical', 'feed', 'calendar')]
    
    if path_parts:
        slug = f"{domain}_{'_'.join(path_parts[:2])}"
    else:
        slug = domain
    
    # Clean up
    slug = re.sub(r'[^a-zA-Z0-9]+', '_', slug).lower().strip('_')
    return slug[:50]  # Limit length


def test_feed(url: str) -> tuple[bool, int]:
    """Test that a feed URL returns valid ICS with events."""
    print(f"\nüß™ Testing feed: {url}")
    
    try:
        result = subprocess.run(
            ['curl', '-sL', '-A', 'Mozilla/5.0', '--max-time', '30', url],
            capture_output=True,
            text=True,
            timeout=35
        )
        
        content = result.stdout
        
        if not content:
            print("‚ùå No response from URL")
            return False, 0
        
        if 'BEGIN:VCALENDAR' not in content:
            print("‚ùå Response is not valid ICS (no BEGIN:VCALENDAR)")
            if len(content) < 500:
                print(f"   Response: {content[:500]}")
            return False, 0
        
        event_count = content.count('BEGIN:VEVENT')
        
        if event_count == 0:
            print("‚ö†Ô∏è  Valid ICS but 0 events (may be normal if no upcoming events)")
        else:
            print(f"‚úÖ Valid ICS with {event_count} events")
        
        return True, event_count
        
    except subprocess.TimeoutExpired:
        print("‚ùå Request timed out after 30 seconds")
        return False, 0
    except Exception as e:
        print(f"‚ùå Error testing feed: {e}")
        return False, 0


def needs_user_agent(url: str) -> bool:
    """Check if URL likely needs a User-Agent header."""
    # Meetup and some WordPress sites need User-Agent
    return any(x in url for x in ['meetup.com', 'site3.ca', 'ontarionature.org'])


def add_to_workflow(url: str, city: str, slug: str) -> bool:
    """Add the curl command to the GitHub Actions workflow."""
    print(f"\nüìù Adding to workflow for city: {city}")
    
    workflow_content = WORKFLOW_PATH.read_text()
    
    # Check if URL already in workflow
    if url in workflow_content:
        print(f"‚úÖ Already in workflow: {url}")
        return True
    
    # Build the curl command
    ua_flag = '-A "Mozilla/5.0" ' if needs_user_agent(url) else ''
    curl_cmd = f'        curl -sL {ua_flag}"{url}" -o {slug}.ics || true'
    
    # Find the Toronto section (or other city)
    # Look for the combine_ics.py line for this city which marks the end of curl commands
    combine_pattern = f'python scripts/combine_ics.py --input-dir cities/{city}'
    
    if combine_pattern not in workflow_content:
        print(f"‚ùå Could not find combine_ics.py section for {city}")
        print(f"   Looking for: {combine_pattern}")
        return False
    
    # Find position and insert before combine_ics.py
    # We need to find the "cd ../.." line that precedes combine_ics.py for this city
    lines = workflow_content.split('\n')
    insert_idx = None
    
    for i, line in enumerate(lines):
        if combine_pattern in line:
            # Walk back to find "cd ../.." 
            for j in range(i-1, max(0, i-5), -1):
                if 'cd ../..' in lines[j]:
                    insert_idx = j
                    break
            break
    
    if insert_idx is None:
        print(f"‚ùå Could not find insertion point for {city}")
        return False
    
    # Insert the curl command before "cd ../.."
    prev_errors = count_actionlint_errors(WORKFLOW_PATH)
    lines.insert(insert_idx, curl_cmd)
    WORKFLOW_PATH.write_text('\n'.join(lines))

    if not validate_workflow(WORKFLOW_PATH, prev_errors):
        print("   Restoring original workflow")
        WORKFLOW_PATH.write_text(workflow_content)
        return False

    print(f"‚úÖ Added to workflow: curl ... -o {slug}.ics")
    return True


def add_to_feeds_txt(url: str, city: str, display_name: str) -> bool:
    """Add the feed URL to cities/{city}/feeds.txt."""
    feeds_path = ROOT / f"cities/{city}/feeds.txt"
    
    print(f"\nüìù Adding to {feeds_path.relative_to(ROOT)}")
    
    if not feeds_path.exists():
        print(f"‚ùå feeds.txt not found: {feeds_path}")
        return False
    
    content = feeds_path.read_text()
    
    # Check if URL already present
    if url in content:
        print(f"‚úÖ Already in feeds.txt")
        return True
    
    # Append the new feed
    entry = f"\n# {display_name}\n{url}\n"
    
    with open(feeds_path, 'a') as f:
        f.write(entry)
    
    print(f"‚úÖ Added to feeds.txt: {display_name}")
    return True


def main():
    parser = argparse.ArgumentParser(
        description='Add an ICS feed to the calendar pipeline',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python scripts/add_feed.py "https://example.com/events/?ical=1" toronto "Example Events"
  python scripts/add_feed.py "https://meetup.com/mygroup/events/ical/" toronto "My Group" --test
  python scripts/add_feed.py URL city "Source Name" --dry-run
"""
    )
    parser.add_argument('url', help='ICS feed URL')
    parser.add_argument('city', help='City directory name (e.g., toronto, santarosa)')
    parser.add_argument('display_name', help='Human-readable source name')
    parser.add_argument('--test', action='store_true', help='Test the feed before adding')
    parser.add_argument('--dry-run', action='store_true', help='Show what would be done without making changes')
    parser.add_argument('--slug', help='Override the auto-generated filename slug')
    
    args = parser.parse_args()
    
    # Generate slug
    slug = args.slug or slugify(args.url)
    
    print(f"üîß Adding feed to {args.city} pipeline")
    print(f"   URL: {args.url}")
    print(f"   Name: {args.display_name}")
    print(f"   Slug: {slug}")
    
    # Test the feed
    if args.test or args.dry_run:
        valid, event_count = test_feed(args.url)
        if not valid and not args.dry_run:
            print("\n‚ö†Ô∏è  Feed test failed. Continue anyway? [y/N] ", end='')
            response = input().strip().lower()
            if response != 'y':
                sys.exit(1)
    
    if args.dry_run:
        ua_flag = '-A "Mozilla/5.0" ' if needs_user_agent(args.url) else ''
        print("\n[DRY RUN] Would perform the following:")
        print(f"  1. Add to workflow: curl -sL {ua_flag}\"{args.url}\" -o {slug}.ics")
        return

    # Add to workflow
    if not add_to_workflow(args.url, args.city, slug):
        print("\n‚ö†Ô∏è  Failed to add to workflow automatically")
        print(f"   Manually add to .github/workflows/generate-calendar.yml:")
        ua_flag = '-A "Mozilla/5.0" ' if needs_user_agent(args.url) else ''
        print(f'   curl -sL {ua_flag}"{args.url}" -o {slug}.ics || true')
    
    print("\n" + "="*60)
    print("‚úÖ Done! Next steps:")
    print("  1. Review changes: git diff")
    print(f"  2. Update SOURCES_CHECKLIST.md if needed")
    print("  3. Commit: git add -A && git commit -m 'Add {display_name} feed'")
    print("  4. Push: git push")
    print("="*60)


if __name__ == '__main__':
    main()
